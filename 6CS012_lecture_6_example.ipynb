{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2yjGUDHd9v-Z",
        "PDKvqc51C9ml",
        "bgRBgXzo97GQ",
        "omjN5HcPBWzk",
        "KSq9vdqjGDPA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression example from lecture"
      ],
      "metadata": {
        "id": "2yjGUDHd9v-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Wlv/7CS033/weight-height.csv')"
      ],
      "metadata": {
        "id": "wlXQB2LVz2uL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "o4MOndihK6as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop('Gender',axis=1)\n",
        "y=df['Gender']"
      ],
      "metadata": {
        "id": "KhD5geo5O8wb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNJzb2rjRss8",
        "outputId": "dfb50db5-320d-4c33-ad02-a74b088df018"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "y=le.fit_transform(y)"
      ],
      "metadata": {
        "id": "gymQmLZ3OtpL"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc=MinMaxScaler()\n",
        "X=sc.fit_transform(X)"
      ],
      "metadata": {
        "id": "uRcu7rNIPTln"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "clf = linear_model.LogisticRegression()\n",
        "fitted_model = clf.fit(X, y)"
      ],
      "metadata": {
        "id": "mJz7JNdOQU7I"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-rw_SjDR7Fs",
        "outputId": "3e466685-0f1f-4337-89af-0a5b5d911a4a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.76889234, 23.66840149]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDu2_FsWShgT",
        "outputId": "f3dd12db-5f74-4d0b-ecb8-904106d22f8a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-10.26391683])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_result = clf.predict([(70,180)])"
      ],
      "metadata": {
        "id": "TvecEeq2RnMo"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyRSuTB3V49W",
        "outputId": "a1dfc49e-70ef-4e3e-9b2b-78bcc79e4e2b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(-1.76889234*70)+(23.66840149*180)+(-10.26391683)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj_E57PPSs0E",
        "outputId": "bf559018-e23e-4d85-9653-af84a4d13d9f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4126.22588757"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression binary classification"
      ],
      "metadata": {
        "id": "PDKvqc51C9ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=4, n_redundant=4, n_classes=2, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "# define the multinomial logistic regression model\n",
        "model = LogisticRegression()\n",
        "# fit the model on the whole dataset\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# predict the class label\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "tMmtRtUEC_mO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "r3Jm4WGLspM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwFnGI_Vta0z",
        "outputId": "d68f8fee-5495-451a-a3fe-4fe7b7b0432a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "aQ3mnPXMDtv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression multi-class classification"
      ],
      "metadata": {
        "id": "bgRBgXzo97GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OvR"
      ],
      "metadata": {
        "id": "yipn6J7O-CLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class=\"ovr\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "uHLBMQOC-Wwn"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OvO"
      ],
      "metadata": {
        "id": "N96_a-7_APFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define the OvO strategy\n",
        "ovo = OneVsOneClassifier(model)\n",
        "\n",
        "# Train the model\n",
        "ovo.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = ovo.predict(X_test)\n"
      ],
      "metadata": {
        "id": "vl5tJH29ARXc"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multinomial"
      ],
      "metadata": {
        "id": "ak9RL3VMAcoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class=\"multinomial\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "yDLJGtCoAe5k"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network binary classification"
      ],
      "metadata": {
        "id": "omjN5HcPBWzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=4, n_redundant=4, n_classes=2, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n"
      ],
      "metadata": {
        "id": "r8oKCIapBbdB"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout\n",
        "from keras import layers\n",
        "from keras.regularizers import l2,l1\n",
        "from sklearn.model_selection import StratifiedKFold as kfold"
      ],
      "metadata": {
        "id": "TxcwkN1zD7Y_"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(10, input_shape=(10,), activation='relu'))\n",
        "model.add(Dense(7,activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "HFBaoxYjEJm_"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DWEQDhr6EVFs"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=50)"
      ],
      "metadata": {
        "id": "rVJQgZyZEuIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss during training\n",
        "from matplotlib import pyplot\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Loss')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot accuracy during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Accuracy')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "cdmz4JXxFLf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network multi class classification"
      ],
      "metadata": {
        "id": "KSq9vdqjGDPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout\n",
        "from keras import layers\n",
        "from keras.regularizers import l2,l1\n",
        "from sklearn.model_selection import StratifiedKFold as kfold\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "-DbMC35HGM9v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "y = to_categorical(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "wXMncD0PGGq6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVVNgQj7GQiH",
        "outputId": "f9c5842c-2fa5-4076-d1aa-1cbf23efee19"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WARNING: Your model works if you use the sigmoid function, but you must use the softmax function\n",
        "model=Sequential()\n",
        "model.add(Dense(10, input_shape=(10,), activation='relu'))\n",
        "model.add(Dense(7,activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "8Ms6UeW-GtnO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WARNING: The model works with binary crossentropy, but you must use categorical_crossentropy\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T23bE0pCG4Z_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=50)"
      ],
      "metadata": {
        "id": "VyH9sTKoHB3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation metrics"
      ],
      "metadata": {
        "id": "8ycd9l4IHfMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the confusion matrics for predictions\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "y_pred=model.predict(X_test)\n",
        "cm1 = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm1,display_labels=['class 1','class 2'])\n",
        "disp.plot()\n",
        "plt.title(\"CM\")"
      ],
      "metadata": {
        "id": "0B8kNMmDH0Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "8rlGvzaXI1kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_metrics (conf_matrix):\n",
        "\n",
        "    TP = conf_matrix[1][1]\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    print('True Positives:', TP)\n",
        "    print('True Negatives:', TN)\n",
        "    print('False Positives:', FP)\n",
        "    print('False Negatives:', FN)\n",
        "\n",
        "    # calculate accuracy\n",
        "    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
        "\n",
        "    # calculate mis-classification\n",
        "    conf_misclassification = 1- conf_accuracy\n",
        "\n",
        "    # calculate the sensitivity\n",
        "    conf_sensitivity = (TP / float(TP + FN))\n",
        "    # calculate the specificity\n",
        "    conf_specificity = (TN / float(TN + FP))\n",
        "\n",
        "    # calculate precision\n",
        "    conf_precision = (TN / float(TN + FP))\n",
        "    # calculate f_1 score\n",
        "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n",
        "    print('-'*50)\n",
        "    print(f'Accuracy: {round(conf_accuracy,2)}')\n",
        "    print(f'Mis-Classification: {round(conf_misclassification,2)}')\n",
        "    print(f'Sensitivity: {round(conf_sensitivity,2)}')\n",
        "    print(f'Specificity: {round(conf_specificity,2)}')\n",
        "    print(f'Precision: {round(conf_precision,2)}')\n",
        "    print(f'f_1 Score: {round(conf_f1,2)}')"
      ],
      "metadata": {
        "id": "X1qwpDMTIdu5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('model metrics\\n')\n",
        "confusion_metrics(cm1)"
      ],
      "metadata": {
        "id": "84nsqS7qJFi2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
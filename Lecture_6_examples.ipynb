{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZcS9U3M2sV_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "text = ['This is the NLP LECTURE written by prof Amin** ','IN this lecture I‚Äùll be explaining various DATA-CLEANING techniques',\n",
        " 'So stay tuned for FURther More &&','Nah I don\"t think he goes to usf, he lives around']\n",
        "df = pd.DataFrame({'text':text})\n"
      ],
      "metadata": {
        "id": "FeQCFl7UDQ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "8eCg0LN1HZys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['lower'] = df['text'].apply(lambda x: \" \".join(x.lower()  for x in x.split()))"
      ],
      "metadata": {
        "id": "CAIj6dvSIHh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "gBlKuO3GJIap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P-8EPC23JtQK",
        "outputId": "d4e9b73c-0e45-44f4-8cf2-9d467fe5f963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rmoving punctuation using string module\n",
        "df.text.apply(lambda x:''.join(i for i in x if i not in string.punctuation))"
      ],
      "metadata": {
        "id": "ApqEzVVcJxHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "pnOECmPhu3I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation using regular expression\n",
        "import re\n",
        "df.lower.apply(lambda x:''.join(re.findall(r'[a-zA-Z+\" \"]',x)))"
      ],
      "metadata": {
        "id": "BIvwxz1nKQoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stop words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "allstopwords = stopwords.words('english')\n",
        "df.lower.apply(lambda x: \" \".join(i for i in x.split() if i not in allstopwords))\n"
      ],
      "metadata": {
        "id": "3pZCVX6zKzH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spelling correction\n",
        "from textblob import TextBlob\n",
        "df['lower'].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "metadata": {
        "id": "njh48E8pMPG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenisation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "mystring = \"My favorite animal is cat\"\n",
        "nltk.word_tokenize(mystring)\n",
        "mystring.split(\" \")"
      ],
      "metadata": {
        "id": "1WoS1ZLPM4M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "df['text'].apply(lambda x:\" \".join([st.stem(word) for word in x.split()]))"
      ],
      "metadata": {
        "id": "S5yQZpG_Oll2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "6UeiUIzyutoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"lemmatisation\"\n",
        "import textblob\n",
        "from textblob import Word\n",
        "df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
      ],
      "metadata": {
        "id": "XmRchTr-P7B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frequency\n",
        "all_words = []\n",
        "for sentence in df['text']:\n",
        "    all_words.extend(sentence.split())\n",
        "import nltk\n",
        "nltk.FreqDist(all_words)\n"
      ],
      "metadata": {
        "id": "37KtZQG9RVYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word cloud\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "words = []\n",
        "for message in df['text']:\n",
        "    words.extend([word for word in message.split() if word not in STOPWORDS])\n",
        "\n",
        "wordcloud = WordCloud(width = 1000, height = 500).generate(\" \".join(words))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NNoSFYAGSM__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text_1 = \"The movie was so awesome.\"\n",
        "text_2 = \"The food here tastes terrible.\"\n",
        "\n",
        "#Determining the Polarity\n",
        "p_1 = TextBlob(text_1).sentiment.polarity\n",
        "p_2 = TextBlob(text_2).sentiment.polarity\n",
        "\n",
        "#Determining the Subjectivity\n",
        "s_1 = TextBlob(text_1).sentiment.subjectivity\n",
        "s_2 = TextBlob(text_2).sentiment.subjectivity\n",
        "\n",
        "print(\"Polarity of Text 1 is\", p_1)\n",
        "print(\"Polarity of Text 2 is\", p_2)\n",
        "print(\"Subjectivity of Text 1 is\", s_1)\n",
        "print(\"Subjectivity of Text 2 is\", s_2)"
      ],
      "metadata": {
        "id": "u2aqlb95W-zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "7jM20036YU_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "sentiment = SentimentIntensityAnalyzer()\n",
        "text_1 = \"The book was a perfect balance between wrtiting style and plot.\"\n",
        "text_2 =  \"The pizza tastes terrible.\"\n",
        "sent_1 = sentiment.polarity_scores(text_1)\n",
        "sent_2 = sentiment.polarity_scores(text_2)\n",
        "print(\"Sentiment of text 1:\", sent_1)\n",
        "print(\"Sentiment of text 2:\", sent_2)"
      ],
      "metadata": {
        "id": "FvhAiHFNQkDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}